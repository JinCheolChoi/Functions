#          "data.table",
#
#          "lme4",
#          "epitools",
#          "doBy" # for esticon function
# ),
# checkpackages)
# lapply(c("geepack"), checkpackages)
# data("respiratory")
# Data_to_use=respiratory
#
# #
# Combined_CT=rbind(
#   Contingency_Table_Generator(Data=Data_to_use,
#                               Row_Var="sex",
#                               Col_Var="outcome",
#                               Ref_of_Row_Var="F",
#                               Missing="Include"),
#   Contingency_Table_Generator_Conti_X(Data=Data_to_use,
#                                       Row_Var="age",
#                                       Col_Var="outcome",
#                                       Missing="Include"),
#   fill=TRUE
#   )
# Combined_CT
#********************************
# Raw_Contingency_Table_Generator
#********************************
# lapply(c("dplyr",
#          "data.table",
#
#          "lme4",
#          "epitools",
#          "geepack"
# ),
# checkpackages)
# data("respiratory")
# Data_to_use=respiratory
#
# # randomly generate NAs in some variables
# Data_to_use$sex[sample(1:nrow(Data_to_use), 30)]=NA
# Data_to_use$age[sample(1:nrow(Data_to_use), 30)]=NA
# Data_to_use$outcome[sample(1:nrow(Data_to_use), 30)]=NA
# #Data_to_use$outcome[sample(1:nrow(Data_to_use), 30)]=2
#
# # Work on predictor with more than 2 levels
# Data_to_use=as.data.table(Data_to_use)
# Data_to_use[age<20, age_cat:="<20"]
# Data_to_use[20<=age & age<30, age_cat:="20<=age<30"]
# Data_to_use[30<=age & age<40, age_cat:="30<=age<40"]
# Data_to_use[40<=age & age<50, age_cat:="40<=age<50"]
# Data_to_use[50<=age & age<60, age_cat:="50<=age<60"]
# Data_to_use[60<=age, age_cat:="60<=age"]
# Data_to_use[, age_cat:=as.factor(age_cat)]
#
# # Data at baseline
# BL_Data=Data_to_use %>%
#   group_by(id) %>%
#   filter(visit==min(visit)) %>%
#   ungroup()
# #
# Table_Data=Raw_Contingency_Table_Generator(Data=Data_to_use,
#                                            Row_Var="outcome",
#                                            Col_Var="age",
#                                            Value="Frequency")
# Raw_Contingency_Table_Generator(Data=Data_to_use,
#                                 Row_Var="outcome",
#                                 Col_Var="age",
#                                 Value="Percentage")
# Line_Graph_Generator(Table_Data[2, 1:(ncol(Table_Data)-1)],
#                      Y_lab="Outcome",
#                      X_lab="Age",
#                      Y_breaks=2)
Raw_Contingency_Table_Generator=function(Data,
Row_Var,
Col_Var,
Value="Frequency"){
# library
library(epitools)
# Data as data table
Data=as.data.frame(Data)
#
Col_Order=c()
if(is.numeric(Data[, Col_Var])==T){
Col_Order=sort(unique(Data[, Col_Var]))
}else if(is.factor(Data[, Col_Var])){
Col_Order=levels(Data[, Col_Var])
}
Data[, Col_Var]=as.character(Data[, Col_Var])
Data[, Row_Var]=as.character(Data[, Row_Var])
# Contingency Table
Contingency_Table=Data %>%
dplyr::select(Row_Var, Col_Var) %>%
table(useNA="no")
# Sum of values column-wise INCLUDING missing data in Row_Var
Sum_Col_Wise=Data %>%
dplyr::select(Col_Var) %>%
table(useNA="no") %>% c
# Sum of values row-wise EXCLUDING missing data in Col_Var
Sum_Row_Wise=apply(Contingency_Table, 1, sum)
# merge all results
if(Value=="Frequency"){
Merged=cbind(Row_Var, rownames(Contingency_Table),
cbind(
paste0(Contingency_Table) %>%
matrix(nrow(Contingency_Table), ncol(Contingency_Table)),
paste0(Sum_Row_Wise)
)
) %>% as.data.frame()
}
if(Value=="Percentage"){
Merged=cbind(Row_Var, rownames(Contingency_Table),
cbind(
paste0(round(t(t(Contingency_Table)/Sum_Col_Wise)*100, 2)) %>%
matrix(nrow(Contingency_Table), ncol(Contingency_Table)),
paste0(round(Sum_Row_Wise/sum(Sum_Col_Wise)*100, 2))
)
) %>% as.data.frame()
}
# post-processing
colnames(Merged)[1:2]=c("Predictor", "Value")
colnames(Merged)[1:2]=c("Predictor", "Value")
colnames(Merged)[3:(3+ncol(Contingency_Table)-1)]=paste0(names(Sum_Col_Wise))
colnames(Merged)[3+ncol(Contingency_Table)]=paste0(sum(Sum_Col_Wise))
Out=Merged
# return
return(Out)
}
#*********************
# Line_Graph_Generator
#*********************
Line_Graph_Generator=function(Table_Data,
Y_lab="Y",
X_lab="X",
Y_breaks=100){
# make plot
Long_Table_Data=melt(Table_Data, id=c("Predictor", "Value"))
colnames(Long_Table_Data)=c("Group", "Nothing", "X", "Y")
Long_Table_Data=as.data.table(Long_Table_Data)
Long_Table_Data[, Y:=as.numeric(Y)]
# plot - all colored
Line_Chart=ggplot(Long_Table_Data, aes(x=X, y=Y, group=Group)) +
geom_line(aes(color=Group))+
geom_point(aes(color=Group))+
ylab(Y_lab)+
xlab(X_lab)+
ylim(0, max(Long_Table_Data[!is.na(Y), Y]))
scale_y_continuous(breaks=seq(0,
max(Long_Table_Data[!is.na(Y), Y]),
Y_breaks))
Line_Chart+theme(axis.text=element_text(size=20),
axis.title=element_text(size=20),
legend.text=element_text(size=15))
}
#**************************************************************
#
# [ --- Markov chain Monte Carlo (MCMC) for sampling --- ] ----
#
#**************************************************************
# Multivariate random-walk Metropolis sampling
#*********************************************
# Run multivariate random-walk Metro-polis sampling
# (I think this is just a regular Metropolis-Hastings sampling for sampling multiple variables)
#********
# Example
#********
# # Define arguments
# # x is a vector
# ring2D=function(x){exp(-5*abs(x[1]^2+x[2]^2-1))}
# vcov2D=.01*diag(2)
# target=ring2D
# N=400
# x=c(0, 0)
# VCOV=vcov2D
# # Call the sampling function with the arguments
# ringsample2D=rwmetro(ring2D, 4000, c(0, 0), vcov2D)
# # Use the sample
# plot(ringsample2D[, 1], ringsample2D[, 2], xlim=c(-1.5, 1.5), ylim=c(-1.5, 1.5), main='Metropolis-Hastings Sample', xlab='x', ylab='y', pch='.')
rwmetro=function(target, N, x, VCOV, burnin=0){
require(MASS)   #requires package MASS for normal sampling
samples=x
for(i in 2:(burnin+N)){
prop=mvrnorm(n=1, x, VCOV)
if(runif(1) < min(1, target(prop)/target(x)))
x=prop
samples=rbind(samples, x)
}
samples[(burnin+1):(N+burnin), ]
}
#*********************
#
# [ --- Etc --- ] ----
#
#*********************
# Stepwise_AIC
#*************
# Example
#********
# lapply(c("stats", "geepack"), checkpackages)
# require(dplyr)
# data("respiratory")
#
# # run GEE_Multivariable
# Full_Model=GLM_Multivariable(Data=respiratory,
#                              Pred_Vars=c("center", "treat", "sex", "age", "baseline"),
#                              Res_Var="outcome",
#                              which.family="gaussian")$model_fit
# Stepwise_AIC(Full_Model)
Stepwise_AIC=function(Full_Model, ...){ # names of people should be numeric
# run model
AIC_Results=stepAIC(Full_Model, ...)
# IndivID_vecual Wald test and confID_vecence interval for each parameter
est=esticon(AIC_Results, diag(length(coef(AIC_Results))))[-1, ]
# Output
Output=c()
Output$model_fit=AIC_Results
Output$vif=car::vif(AIC_Results)
if(which.family=="gaussian"){
Output$summ_table=data.frame(Estimate=round2(est$estimate, 3),
Std.Error=round2(est$std.error, 3),
`P-value`=ifelse(round2(est$p.value, 3)<0.001, "<0.001",
format(round2(est$p.value, 3), nsmall=3)),
Estimate.and.CI=paste0(format(round2(est$estimate, 2), nsmall=2),
" (", format(round2(est$estimate-qnorm(0.975)*est$std.error, 2), nsmall=2), " - ",
format(round2(est$estimate+qnorm(0.975)*est$std.error, 2), nsmall=2), ")"),
row.names=names(coef(AIC_Results))[-1]
)
}else if(which.family=="binomial"){
Output$summ_table=data.frame(Estimate=round2(est$estimate, 3),
Std.Error=round2(est$std.error, 3),
`P-value`=ifelse(round2(est$p.value, 3)<0.001, "<0.001",
format(round2(est$p.value, 3), nsmall=3)),
OR.and.CI=paste0(format(round2(exp(est$estimate), 2), nsmall=2),
" (", format(round2(exp(est$estimate-qnorm(0.975)*est$std.error), 2), nsmall=2), " - ",
format(round2(exp(est$estimate+qnorm(0.975)*est$std.error), 2), nsmall=2), ")"),
row.names=names(coef(AIC_Results))[-1]
)
}else if(which.family=="poisson"){
Output$summ_table=data.frame(Estimate=round2(est$estimate, 3),
Std.Error=round2(est$std.error, 3),
`P-value`=ifelse(round2(est$p.value, 3)<0.001, "<0.001",
format(round2(est$p.value, 3), nsmall=3)),
RR.and.CI=paste0(format(round2(exp(est$estimate), 2), nsmall=2),
" (", format(round2(exp(est$estimate-qnorm(0.975)*est$std.error), 2), nsmall=2), " - ",
format(round2(exp(est$estimate+qnorm(0.975)*est$std.error), 2), nsmall=2), ")"),
row.names=names(coef(AIC_Results))[-1]
)
}
return(Output)
}
#********************
# Mortgage_Calculator
#********************
# Example
#********
# Mortgage_Calculator(HP=1000000, DP=200000,
#                     ANIR=0.04, AP=25,
#                     ID="2020-02-01", PF="Monthly")
Mortgage_Calculator=function(HP=500000,          # House Price
DP=100000,          # Down Payment
ANIR=0.04,          # Annual Nominal Interest Rate
AP=15,              # Amortization Period (years)
ID="2020-02-01",    # Initial Date of Amortization
PF="Monthly"){      # "Monthly"|"Bi-Weekly"
IP=HP-DP # Initial Principal
if(PF=="Monthly"){
AA=12 # Annual_Amortization
}else if(PF=="Bi-Weekly"){
AA=26
}
IR=((1+(ANIR/2))^2)^(1/AA)-1 # Interest Rate
PP=(IP*IR)/(1-(1+IR)^(-AP*AA)) # Periodic Payment
# generate Amortization Schedule Worksheet
Periodic_Table=data.table(
)
if(PF=="Monthly"){Periodic_Table[, Date:=seq(as.Date(ID), by="1 month", length=(AP*AA)+1)]}
if(PF=="Bi-Weekly"){Periodic_Table[, Date:=seq(as.Date(ID), by="2 weeks", length=(AP*AA)+1)]}
Periodic_Table[, Payment:=c(0, rep(PP, AP*AA))]
for(i in 1:(AA*AP+1)){
if(i==1){
Periodic_Table[i, Interest:=0]
Periodic_Table[i, Principal:=0]
Periodic_Table[i, Balance:=IP] # Remaining Principal
}else{
Periodic_Table[i, Interest:=IR*Periodic_Table[i-1, Balance]]
Periodic_Table[i, Principal:=round(Payment-Interest, 2)]
Periodic_Table[i, Balance:=round(Periodic_Table[i-1, Balance]-Principal)]
}
}
return(as.data.table(Periodic_Table))
}
#*********
# Joy_Plot
#*********
# Example
#********
# lapply(c("geepack"), checkpackages)
# data("respiratory")
# Data_to_use=respiratory
#
# Joy_Plot(Data=Data_to_use,
#          X_Var="age",
#          Y_Var="sex",
#          scale=2,
#          rel_min_height=0.0001)
Joy_Plot=function(Data, X_Var, Y_Var, ...){
lapply(c("ggridges",
"ggplot2",
"viridis",
"hrbrthemes"),
checkpackages)
Data=as.data.frame(Data)
Data[, X_Var]=as.numeric(Data[, X_Var])
Data[, Y_Var]=as.factor(Data[, Y_Var])
ggplot(Data, aes(x=eval(parse(text=X_Var)), y=eval(parse(text=Y_Var)), fill=..x..))+
geom_density_ridges_gradient(...)+
xlab(X_Var)+
ylab(Y_Var)+
scale_fill_viridis(name="X_Var", option="C")
}
#**************
# mclapply.hack
#**************
# Example
#********
# lapply(c("parallel"), checkpackages)
# wait.longer.then.square=function(xx){
#   ## Wait for ten seconds
#   Sys.sleep(10);
#   ## Square the argument
#   xx^2}
#
# (a.global.variable=diag(3))
#
# system.time({serial.output=lapply(1:4,
#                                  function(xx){
#                                    return(wait.longer.then.square(xx)+a.global.variable)
#                                  })})
#
# system.time({par.output=mclapply.hack(1:4,
#                                      function(xx){
#                                        return(wait.longer.then.square(xx)+a.global.variable)
#                                      })})
mclapply.hack=function(...){
## Create a cluster
## ... How many workers do you need?
## ... N.B. list(...)[[1]] returns the first
##          argument passed to the function. In
##          this case it is the list to iterate over
size.of.list=length(list(...)[[1]])
cl=makeCluster(min(size.of.list, detectCores()))
## Find out the names of the loaded packages
loaded.package.names=c(
## Base packages
sessionInfo()$basePkgs,
## Additional packages
names(sessionInfo()$otherPkgs))
## N.B. tryCatch()allows us to properly shut down the
##      cluster if an error in our code halts execution
##      of the function. For details see: help(tryCatch)
tryCatch({
## Copy over all of the objects within scope to
## all clusters.
##
## The approach is as follows: Beginning with the
## current environment, copy over all objects within
## the environment to all clusters, and then repeat
## the process with the parent environment.
##
this.env=environment()
while(identical(this.env, globalenv())==FALSE){
clusterExport(cl,
ls(all.names=TRUE, env=this.env),
envir=this.env)
this.env=parent.env(environment())
}
## repeat for the global environment
clusterExport(cl,
ls(all.names=TRUE, env=globalenv()),
envir=globalenv())
## Load the libraries on all the clusters
## N.B. length(cl)returns the number of clusters
parLapply(cl, 1:length(cl), function(xx){
lapply(loaded.package.names, function(yy){
## N.B. the character.only option of
##      require()allows you to give the
##      name of a package as a string.
require(yy , character.only=TRUE)})
})
## Run the lapply in parallel
return(parLapply(cl, ...))
}, finally={
## Stop the cluster
stopCluster(cl)
})
}
#**********************
# Example of doParallel
#**********************
# lapply(c("foreach", "doParallel"), checkpackages)
# numCores=detectCores()
# registerDoParallel(numCores)  # use multicore, set to the number of our cores
#
# # 1 - use lapply
# x=iris[which(iris[,5]!="setosa"), c(1,5)]
# trials=seq(1, 10000)
# boot_fx=function(trial){
#   ind=sample(100, 100, replace=TRUE)
#   result1=glm(x[ind,2]~x[ind,1], family=binomial(logit))
#   r=coefficients(result1)
#   res=rbind(data.frame(), r)
# }
# system.time({
#   results=lapply(trials, boot_fx)
# })
#
# # 2 - use foreach - compare that to what it takes to do the same analysis in serial
# trials=10000
# system.time({
#   r=foreach(icount(trials), .combine=rbind)%do%{
#     ind=sample(100, 100, replace=TRUE)
#     result1=glm(x[ind,2]~x[ind,1], family=binomial(logit))
#     coefficients(result1)
#   }
# })
#
# # 3 - use a parallel bootstrap
# # From the doParallel vignette, but slightly modified
# trials=10000
# system.time({
#   r.2=foreach(icount(trials), .combine=rbind)%dopar%{
#     ind=sample(100, 100, replace=TRUE)
#     result1=glm(x[ind,2]~x[ind,1], family=binomial(logit))
#     coefficients(result1)
#   }
# })
#
# # When you're done, clean up the cluster
# stopImplicitCluster()
lapply(c("dplyr",
"data.table",
"lme4",
"epitools",
"doBy" # for esticon function
),
checkpackages)
lapply(c("geepack"), checkpackages)
data("respiratory")
Data_to_use=respiratory
# randomly generate NAs in some variables
Data_to_use$age[sample(1:nrow(Data_to_use), 30)]=NA
Data_to_use$outcome[sample(1:nrow(Data_to_use), 30)]=NA
#Data_to_use$outcome[sample(1:nrow(Data_to_use), 30)]="2"
# Data at baseline
BL_Data=Data_to_use %>%
group_by(id) %>%
filter(visit==min(visit)) %>%
ungroup()
#
Contingency_Table_Generator_Conti_X(Data=BL_Data,
Row_Var="age",
Col_Var="outcome",
Missing="Include")
Contingency_Table_Generator_Conti_X(Data=BL_Data,
Row_Var="age",
Col_Var="outcome",
Missing="Not_Include")
library(slalom)
library(slalom)
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("slalom")
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.10")
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("slalom")
biocLite
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.10")
library(BiocManager)
library(BiocManager)
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("slalom")
library(BiocManager)
library(BiocManager)
biocLite
BiocManager::install(version = "3.10")
version(bit)
rversions::
R.version
BiocManager::install()
Bioconductor
BiocManager
biocLite("slalom")
biocLite
BiocManager::install("slalom")
library(mvtnorm)
n=100 # sample size
p=4   # number of predictors
q=2   # number of responses
sigma=diag(1, p+q) # covariance matrix
sigma[4, 2]=sigma[2, 4]=0.7
D=rmvnorm(n=n, mean=rep(0, p+q), sigma=sigma) # data generated
Contribution_plot(X=D[, 3:6], Y=D[, 1:2], alpha= c(1:5), nrep=500)
